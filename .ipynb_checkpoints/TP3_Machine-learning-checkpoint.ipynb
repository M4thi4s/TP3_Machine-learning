{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Présentation du TP sur la classification de films\n",
    "\n",
    "L'objectif de ce TP est d'identifier le genre d'un film à partir de son résumé.\n",
    "\n",
    "Le TP se fera en binôme et le notebook sera à déposer sur madoc pour le **vendredi 08/04/2022**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pré-traitement et visualisation des données \n",
    "\n",
    "Les données correspondent aux 1000 films les plus populaires d'IMDB, entre 2006 et 2016 ([imdb-data](https://www.kaggle.com/datasets/PromptCloudHQ/imdb-data)).  \n",
    "\n",
    "Dans cette première partie du TP, vous devrez récupérer les données et les stocker dans un dataframe puis effectuer quelques visualisations de celles-ci."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des données dans un dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/IMDB-Movie-Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/E207253A/reseau/Perso/Documents/Deuxieme_annee/S4/TPRO/TP3_Machine-learning/.ipynb_checkpoints/TP3_Machine-learning-checkpoint.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/E207253A/reseau/Perso/Documents/Deuxieme_annee/S4/TPRO/TP3_Machine-learning/.ipynb_checkpoints/TP3_Machine-learning-checkpoint.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/E207253A/reseau/Perso/Documents/Deuxieme_annee/S4/TPRO/TP3_Machine-learning/.ipynb_checkpoints/TP3_Machine-learning-checkpoint.ipynb#ch0000003?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m./data/IMDB-Movie-Data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/E207253A/reseau/Perso/Documents/Deuxieme_annee/S4/TPRO/TP3_Machine-learning/.ipynb_checkpoints/TP3_Machine-learning-checkpoint.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(df)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers.py:688\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=634'>635</a>\u001b[0m     engine_specified \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=636'>637</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=637'>638</a>\u001b[0m     delimiter\u001b[39m=\u001b[39mdelimiter,\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=638'>639</a>\u001b[0m     engine\u001b[39m=\u001b[39mengine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=684'>685</a>\u001b[0m     skip_blank_lines\u001b[39m=\u001b[39mskip_blank_lines,\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=685'>686</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=687'>688</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers.py:454\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=450'>451</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=452'>453</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=453'>454</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(fp_or_buf, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=455'>456</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=456'>457</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers.py:948\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=944'>945</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwds:\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=945'>946</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=947'>948</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers.py:1180\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=1177'>1178</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_engine\u001b[39m(\u001b[39mself\u001b[39m, engine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=1178'>1179</a>\u001b[0m     \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mc\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=1179'>1180</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m CParserWrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=1180'>1181</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=1181'>1182</a>\u001b[0m         \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers.py:2010\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=2006'>2007</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols_dtype \u001b[39m=\u001b[39m _validate_usecols_arg(kwds[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=2007'>2008</a>\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols\n\u001b[0;32m-> <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=2009'>2010</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=2010'>2011</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[1;32m   <a href='file:///usr/lib/python3/dist-packages/pandas/io/parsers.py?line=2012'>2013</a>\u001b[0m passed_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:382\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:674\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/IMDB-Movie-Data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('./data/IMDB-Movie-Data.csv')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage des 10 premiers films\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage du nombre de films de chaque genre\n",
    "\n",
    "Certains films sont associés à plusieurs genres : ils devront donc être comptabilisés dans chacun des genres (un genre est représenté par un seul mot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage du nombre de films par genre et par année\n",
    "\n",
    "Afficher un histogramme donnant la répartition du nombre de films par genre, pour chaque année."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un dataframe contenant uniquement le titre du film, son résumé ainsi que son genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Classification binaire d'un genre de film choisi\n",
    "\n",
    "Vous devrez tout d'abord choisir un genre de films parmi ceux présents dans les données. L'objectif sera ensuite de créer un classifieur permettant d'indiquer si un film appartient au genre choisi, en utilisant la description du film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout d'une colonne correspondant à l'appartenance ou non du film au genre choisi\n",
    "\n",
    "Le genre choisi pour la suite est **indiquer ici le genre choisi**.\n",
    "\n",
    "Si le film appartient à ce genre, il aura la valeur 1 dans cette nouvelle colonne et il aura la valeur 0 dans le cas contraire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des données en un ensemble d'apprentissage (80% des données) et un ensemble de test (20% des données)\n",
    "Les classes devront être équilibrées, c'est-à-dire que le genre choisi doit avoir la même représentativité, dans l'ensemble d'apprentissage et dans l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification des 10 mots les plus caractéristiques du genre choisi (mots les plus fréquents pour le genre choisi et qui apparaissent peu ou pas dans les descriptions des films des autres genres) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer une nouvelle représentation des données, dans un nouveau dataframe, en indiquant le nombre d'occurrences de chaque mot caractéristique du genre, dans le résumé du film\n",
    "Chaque film sera ainsi décrit par une colonne indiquant son nom, une colonne indiquant s'il appartient ou non au genre choisi et autant de colonnes que de mots caractéristiques (l'en-tête de chacune de ces colonnes sera le mot choisi et, pour chaque ligne correspondant à un film, on aura le nombre d'occurrences du mot dans le résumé du film correspondant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de différents classifieurs pour identifier le genre de film choisi (k-plus-proches-voisins, SVM, classification naïve de Bayes...).\n",
    "\n",
    "Vous afficherez les performances et la matrice de confusion pour le meilleur classifieur de chaque type. Vous pourrez également utiliser de la validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utilisation d'autres caractéristiques pour représenter les films (pour aller plus loin et avoir plus de points)\n",
    "\n",
    "Vous avez décrit les films par les 10 mots les plus représentatifs du genre choisi mais les films pourraient être décrits par d'autres caractéristiques (voir le fichier \"chapter4_BuildingAFakeNewsClassifier.pdf\", par exemple). Vous pouvez reprendre la partie précédente, en utilisation une représentation des films qui prend en compte l'ensemble des mots de leur résumé, après d'éventuels pré-traitements sur les mots (voir \"spacy_cheatSheet.pdf\" et le site web de [spaCy](https://spacy.io))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
